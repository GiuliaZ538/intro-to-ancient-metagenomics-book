@article{Wratten2021-es,
  title     = {Reproducible, scalable, and shareable analysis pipelines with
               bioinformatics workflow managers},
  author    = {Wratten, Laura and Wilm, Andreas and Göke, Jonathan},
  journal   = {Nature methods},
  publisher = {Springer Science and Business Media LLC},
  volume    = 18,
  number    = 10,
  pages     = {1161--1168},
  abstract  = {The rapid growth of high-throughput technologies has transformed
               biomedical research. With the increasing amount and complexity of
               data, scalability and reproducibility have become essential not
               just for experiments, but also for computational analysis.
               However, transforming data into information involves running a
               large number of tools, optimizing parameters, and integrating
               dynamically changing reference data. Workflow managers were
               developed in response to such challenges. They simplify pipeline
               development, optimize resource usage, handle software
               installation and versions, and run on different compute
               platforms, enabling workflow portability and sharing. In this
               Perspective, we highlight key features of workflow managers,
               compare commonly used approaches for bioinformatics workflows,
               and provide a guide for computational and noncomputational users.
               We outline community-curated pipeline initiatives that enable
               novice and experienced users to perform complex, best-practice
               analyses without having to manually assemble workflows. In sum,
               we illustrate how workflow managers contribute to making
               computational analysis in biomedical research shareable,
               scalable, and reproducible.},
  month     = oct,
  year      = 2021,
  url       = {https://www.nature.com/articles/s41592-021-01254-9},
  doi       = {10.1038/s41592-021-01254-9},
  pmid      = 34556866,
  issn      = {1548-7091,1548-7105},
  language  = {en}
}

@article{Fellows_Yates2021-jl,
  title     = {Reproducible, portable, and efficient ancient genome
               reconstruction with nf-core/eager},
  author    = {Fellows Yates, James A and Lamnidis, Thiseas C and Borry, Maxime
               and Andrades Valtueña, Aida and Fagernäs, Zandra and Clayton,
               Stephen and Garcia, Maxime U and Neukamm, Judith and Peltzer,
               Alexander},
  journal   = {PeerJ},
  publisher = {PeerJ Inc.},
  volume    = 9,
  pages     = {e10947},
  abstract  = {The broadening utilisation of ancient DNA to address
               archaeological, palaeontological, and biological questions is
               resulting in a rising diversity in the size of laboratories and
               scale of analyses being performed. In the context of this
               heterogeneous landscape, we present an advanced, and entirely
               redesigned and extended version of the EAGER pipeline for the
               analysis of ancient genomic data. This Nextflow pipeline aims to
               address three main themes: accessibility and adaptability to
               different computing configurations, reproducibility to ensure
               robust analytical standards, and updating the pipeline to the
               latest routine ancient genomic practices. The new version of
               EAGER has been developed within the nf-core initiative to ensure
               high-quality software development and maintenance support;
               contributing to a long-term life-cycle for the pipeline.
               nf-core/eager will assist in ensuring that a wider range of
               ancient DNA analyses can be applied by a diverse range of
               research groups and fields.},
  month     = mar,
  year      = 2021,
  url       = {http://dx.doi.org/10.7717/peerj.10947},
  keywords  = {Bioinformatics; Palaeogenomics; Ancient DNA; Pipeline; Nextflow;
               Reproducibility; Genomics; Metagenomics},
  doi       = {10.7717/peerj.10947},
  pmc       = {PMC7977378},
  pmid      = 33777521,
  issn      = {2167-8359},
  language  = {en}
}

@unpublished{Pochon2022-hj,
  title    = {{aMeta}: an accurate and memory-efficient ancient Metagenomic
              profiling workflow},
  author   = {Pochon, Zoé and Bergfeldt, Nora and Kırdök, Emrah and Vicente,
              Mário and Naidoo, Thijessen and van der Valk, Tom and Ezgi
              Altınışık, N and Krzewińska, Maja and Dalen, Love and Götherström,
              Anders and Mirabello, Claudio and Unneberg, Per and Oskolkov,
              Nikolay},
  journal  = {bioRxiv},
  pages    = {2022.10.03.510579},
  abstract = {Analysis of microbial data from archaeological samples is a
              rapidly growing field with a great potential for understanding
              ancient environments, lifestyles and disease spread in the past.
              However, high error rates have been a long-standing challenge in
              ancient metagenomics analysis. This is also complicated by a
              limited choice of ancient microbiome specific computational
              frameworks that meet the growing computational demands of the
              field. Here, we propose aMeta, an accurate ancient Metagenomic
              profiling workflow designed primarily to minimize the amount of
              false discoveries and computer memory requirements. Using
              simulated ancient metagenomic samples, we benchmark aMeta against
              a current state-of-the-art workflow, and demonstrate its superior
              sensitivity and specificity in both microbial detection and
              authentication, as well as substantially lower usage of computer
              memory. aMeta is implemented as a Snakemake workflow to facilitate
              use and reproducibility. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.},
  month    = oct,
  year     = 2022,
  url      = {https://www.biorxiv.org/content/10.1101/2022.10.03.510579v1},
  doi      = {10.1101/2022.10.03.510579},
  language = {en}
}

@article{Krakau2022-we,
  title     = {nf-core/mag: a best-practice pipeline for metagenome hybrid
               assembly and binning},
  author    = {Krakau, Sabrina and Straub, Daniel and Gourlé, Hadrien and
               Gabernet, Gisela and Nahnsen, Sven},
  journal   = {NAR Genomics and Bioinformatics},
  publisher = {Oxford Academic},
  volume    = 4,
  number    = 1,
  abstract  = {Abstract. The analysis of shotgun metagenomic data provides
               valuable insights into microbial communities, while allowing
               resolution at individual genome level.},
  month     = jan,
  year      = 2022,
  url       = {https://academic.oup.com/nargab/article-pdf/4/1/lqac007/42366621/lqac007.pdf},
  doi       = {10.1093/nargab/lqac007}
}

@article{Andrades_Valtuena2022-tq,
  title     = {Stone Age Yersinia pestis genomes shed light on the early
               evolution, diversity, and ecology of plague},
  author    = {Andrades Valtueña, Aida and Neumann, Gunnar U and Spyrou, Maria A
               and Musralina, Lyazzat and Aron, Franziska and Beisenov, Arman
               and Belinskiy, Andrey B and Bos, Kirsten I and Buzhilova,
               Alexandra and Conrad, Matthias and Djansugurova, Leyla B and
               Dobeš, Miroslav and Ernée, Michal and Fernández-Eraso, Javier and
               Frohlich, Bruno and Furmanek, Mirosław and Hałuszko, Agata and
               Hansen, Svend and Harney, Éadaoin and Hiss, Alina N and Hübner,
               Alexander and Key, Felix M and Khussainova, Elmira and Kitov,
               Egor and Kitova, Alexandra O and Knipper, Corina and Kühnert,
               Denise and Lalueza-Fox, Carles and Littleton, Judith and Massy,
               Ken and Mittnik, Alissa and Mujika-Alustiza, José Antonio and
               Olalde, Iñigo and Papac, Luka and Penske, Sandra and Peška,
               Jaroslav and Pinhasi, Ron and Reich, David and Reinhold, Sabine
               and Stahl, Raphaela and Stäuble, Harald and Tukhbatova, Rezeda I
               and Vasilyev, Sergey and Veselovskaya, Elizaveta and Warinner,
               Christina and Stockhammer, Philipp W and Haak, Wolfgang and
               Krause, Johannes and Herbig, Alexander},
  journal   = {Proceedings of the National Academy of Sciences of the United
               States of America},
  publisher = {Proceedings of the National Academy of Sciences},
  volume    = 119,
  number    = 17,
  pages     = {e2116722119},
  abstract  = {The bacterial pathogen Yersinia pestis gave rise to devastating
               outbreaks throughout human history, and ancient DNA evidence has
               shown it afflicted human populations as far back as the
               Neolithic. Y. pestis genomes recovered from the Eurasian Late
               Neolithic/Early Bronze Age (LNBA) period have uncovered key
               evolutionary steps that led to its emergence from a Yersinia
               pseudotuberculosis-like progenitor; however, the number of
               reconstructed LNBA genomes are too few to explore its diversity
               during this critical period of development. Here, we present 17
               Y. pestis genomes dating to 5,000 to 2,500 y BP from a wide
               geographic expanse across Eurasia. This increased dataset enabled
               us to explore correlations between temporal, geographical, and
               genetic distance. Our results suggest a nonflea-adapted and
               potentially extinct single lineage that persisted over millennia
               without significant parallel diversification, accompanied by
               rapid dispersal across continents throughout this period, a trend
               not observed in other pathogens for which ancient genomes are
               available. A stepwise pattern of gene loss provides further clues
               on its early evolution and potential adaptation. We also discover
               the presence of the flea-adapted form of Y. pestis in Bronze Age
               Iberia, previously only identified in in the Caucasus and the
               Volga regions, suggesting a much wider geographic spread of this
               form of Y. pestis. Together, these data reveal the dynamic nature
               of plague’s formative years in terms of its early evolution and
               ecology.},
  month     = apr,
  year      = 2022,
  url       = {https://www.pnas.org/doi/abs/10.1073/pnas.2116722119},
  keywords  = {Yersinia pestis; ancient DNA; plague},
  doi       = {10.1073/pnas.2116722119},
  pmc       = {PMC9169917},
  pmid      = 35412864,
  issn      = {0027-8424,1091-6490},
  language  = {en}
}

@article{Dimopoulos2022-tp,
  title     = {{HAYSTAC}: A Bayesian framework for robust and rapid species
               identification in high-throughput sequencing data},
  author    = {Dimopoulos, Evangelos A and Carmagnini, Alberto and Velsko, Irina
               M and Warinner, Christina and Larson, Greger and Frantz, Laurent
               A F and Irving-Pease, Evan K},
  journal   = {PLoS computational biology},
  publisher = {Public Library of Science (PLoS)},
  volume    = 18,
  number    = 9,
  pages     = {e1010493},
  abstract  = {Identification of specific species in metagenomic samples is
               critical for several key applications, yet many tools available
               require large computational power and are often prone to false
               positive identifications. Here we describe High-AccuracY and
               Scalable Taxonomic Assignment of MetagenomiC data (HAYSTAC),
               which can estimate the probability that a specific taxon is
               present in a metagenome. HAYSTAC provides a user-friendly tool to
               construct databases, based on publicly available genomes, that
               are used for competitive read mapping. It then uses a novel
               Bayesian framework to infer the abundance and statistical support
               for each species identification and provide per-read species
               classification. Unlike other methods, HAYSTAC is specifically
               designed to efficiently handle both ancient and modern DNA data,
               as well as incomplete reference databases, making it possible to
               run highly accurate hypothesis-driven analyses (i.e., assessing
               the presence of a specific species) on variably sized reference
               databases while dramatically improving processing speeds. We
               tested the performance and accuracy of HAYSTAC using simulated
               Illumina libraries, both with and without ancient DNA damage, and
               compared the results to other currently available methods (i.e.,
               Kraken2/Bracken, KrakenUniq, MALT/HOPS, and Sigma). HAYSTAC
               identified fewer false positives than both Kraken2/Bracken,
               KrakenUniq and MALT in all simulations, and fewer than Sigma in
               simulations of ancient data. It uses less memory than
               Kraken2/Bracken, KrakenUniq as well as MALT both during database
               construction and sample analysis. Lastly, we used HAYSTAC to
               search for specific pathogens in two published ancient
               metagenomic datasets, demonstrating how it can be applied to
               empirical datasets. HAYSTAC is available from
               https://github.com/antonisdim/HAYSTAC.},
  month     = sep,
  year      = 2022,
  url       = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010493},
  doi       = {10.1371/journal.pcbi.1010493},
  pmc       = {PMC9555677},
  pmid      = 36178955,
  issn      = {1553-734X,1553-7358},
  language  = {en}
}

@article{Hubler2019-qw,
  title    = {{HOPS}: automated detection and authentication of pathogen {DNA}
              in archaeological remains},
  author   = {Hübler, Ron and Key, Felix M and Warinner, Christina and Bos,
              Kirsten I and Krause, Johannes and Herbig, Alexander},
  journal  = {Genome Biology},
  volume   = 20,
  number   = 1,
  pages    = 280,
  abstract = {High-throughput DNA sequencing enables large-scale metagenomic
              analyses of complex biological systems. Such analyses are not
              restricted to present-day samples and can also be applied to
              molecular data from archaeological remains. Investigations of
              ancient microbes can provide valuable information on past
              bacterial commensals and pathogens, but their molecular detection
              remains a challenge. Here, we present HOPS (Heuristic Operations
              for Pathogen Screening), an automated bacterial screening pipeline
              for ancient DNA sequences that provides detailed information on
              species identification and authenticity. HOPS is a versatile tool
              for high-throughput screening of DNA from archaeological material
              to identify candidates for genome-level analyses.},
  month    = dec,
  year     = 2019,
  url      = {https://doi.org/10.1186/s13059-019-1903-0},
  doi      = {10.1186/s13059-019-1903-0},
  issn     = {1474-760X}
}

@article{Louvel2016-jo,
  title    = {{metaBIT}, an integrative and automated metagenomic pipeline for
              analysing microbial profiles from high-throughput sequencing
              shotgun data},
  author   = {Louvel, Guillaume and Der Sarkissian, Clio and Hanghøj, Kristian
              and Orlando, Ludovic},
  journal  = {Molecular ecology resources},
  volume   = 16,
  number   = 6,
  pages    = {1415--1427},
  abstract = {Micro-organisms account for most of the Earth's biodiversity and
              yet remain largely unknown. The complexity and diversity of
              microbial communities present in clinical and environmental
              samples can now be robustly investigated in record times and
              prices thanks to recent advances in high-throughput DNA sequencing
              (HTS). Here, we develop metaBIT, an open-source computational
              pipeline automatizing routine microbial profiling of shotgun HTS
              data. Customizable by the user at different stringency levels, it
              performs robust taxonomy-based assignment and relative abundance
              calculation of microbial taxa, as well as cross-sample statistical
              analyses of microbial diversity distributions. We demonstrate the
              versatility of metaBIT within a range of published HTS data sets
              sampled from the environment (soil and seawater) and the human
              body (skin and gut), but also from archaeological specimens. We
              present the diversity of outputs provided by the pipeline for the
              visualization of microbial profiles (barplots, heatmaps) and for
              their characterization and comparison (diversity indices,
              hierarchical clustering and principal coordinates analyses). We
              show that metaBIT allows an automatic, fast and user-friendly
              profiling of the microbial DNA present in HTS shotgun data sets.
              The applications of metaBIT are vast, from monitoring of
              laboratory errors and contaminations, to the reconstruction of
              past and present microbiota, and the detection of candidate
              species, including pathogens.},
  month    = nov,
  year     = 2016,
  url      = {http://dx.doi.org/10.1111/1755-0998.12546},
  keywords = {Metagenomics; Microbiome; microbial profiling; shotgun sequencing;
              ancient DNA},
  doi      = {10.1111/1755-0998.12546},
  pmid     = 27238636,
  issn     = {1755-098X,1755-0998},
  language = {en}
}

@article{Louvel2016-jo,
  title    = {{metaBIT}, an integrative and automated metagenomic pipeline for
              analysing microbial profiles from high-throughput sequencing
              shotgun data},
  author   = {Louvel, Guillaume and Der Sarkissian, Clio and Hanghøj, Kristian
              and Orlando, Ludovic},
  journal  = {Molecular ecology resources},
  volume   = 16,
  number   = 6,
  pages    = {1415--1427},
  abstract = {Micro-organisms account for most of the Earth's biodiversity and
              yet remain largely unknown. The complexity and diversity of
              microbial communities present in clinical and environmental
              samples can now be robustly investigated in record times and
              prices thanks to recent advances in high-throughput DNA sequencing
              (HTS). Here, we develop metaBIT, an open-source computational
              pipeline automatizing routine microbial profiling of shotgun HTS
              data. Customizable by the user at different stringency levels, it
              performs robust taxonomy-based assignment and relative abundance
              calculation of microbial taxa, as well as cross-sample statistical
              analyses of microbial diversity distributions. We demonstrate the
              versatility of metaBIT within a range of published HTS data sets
              sampled from the environment (soil and seawater) and the human
              body (skin and gut), but also from archaeological specimens. We
              present the diversity of outputs provided by the pipeline for the
              visualization of microbial profiles (barplots, heatmaps) and for
              their characterization and comparison (diversity indices,
              hierarchical clustering and principal coordinates analyses). We
              show that metaBIT allows an automatic, fast and user-friendly
              profiling of the microbial DNA present in HTS shotgun data sets.
              The applications of metaBIT are vast, from monitoring of
              laboratory errors and contaminations, to the reconstruction of
              past and present microbiota, and the detection of candidate
              species, including pathogens.},
  month    = nov,
  year     = 2016,
  url      = {http://dx.doi.org/10.1111/1755-0998.12546},
  keywords = {Metagenomics; Microbiome; microbial profiling; shotgun sequencing;
              ancient DNA},
  doi      = {10.1111/1755-0998.12546},
  pmid     = 27238636,
  issn     = {1755-098X,1755-0998},
  language = {en}
}

@article{Louvel2016-jo,
  title    = {{metaBIT}, an integrative and automated metagenomic pipeline for
              analysing microbial profiles from high-throughput sequencing
              shotgun data},
  author   = {Louvel, Guillaume and Der Sarkissian, Clio and Hanghøj, Kristian
              and Orlando, Ludovic},
  journal  = {Molecular ecology resources},
  volume   = 16,
  number   = 6,
  pages    = {1415--1427},
  abstract = {Micro-organisms account for most of the Earth's biodiversity and
              yet remain largely unknown. The complexity and diversity of
              microbial communities present in clinical and environmental
              samples can now be robustly investigated in record times and
              prices thanks to recent advances in high-throughput DNA sequencing
              (HTS). Here, we develop metaBIT, an open-source computational
              pipeline automatizing routine microbial profiling of shotgun HTS
              data. Customizable by the user at different stringency levels, it
              performs robust taxonomy-based assignment and relative abundance
              calculation of microbial taxa, as well as cross-sample statistical
              analyses of microbial diversity distributions. We demonstrate the
              versatility of metaBIT within a range of published HTS data sets
              sampled from the environment (soil and seawater) and the human
              body (skin and gut), but also from archaeological specimens. We
              present the diversity of outputs provided by the pipeline for the
              visualization of microbial profiles (barplots, heatmaps) and for
              their characterization and comparison (diversity indices,
              hierarchical clustering and principal coordinates analyses). We
              show that metaBIT allows an automatic, fast and user-friendly
              profiling of the microbial DNA present in HTS shotgun data sets.
              The applications of metaBIT are vast, from monitoring of
              laboratory errors and contaminations, to the reconstruction of
              past and present microbiota, and the detection of candidate
              species, including pathogens.},
  month    = nov,
  year     = 2016,
  url      = {http://dx.doi.org/10.1111/1755-0998.12546},
  keywords = {Metagenomics; Microbiome; microbial profiling; shotgun sequencing;
              ancient DNA},
  doi      = {10.1111/1755-0998.12546},
  pmid     = 27238636,
  issn     = {1755-098X,1755-0998},
  language = {en}
}

@article{Schubert2014-ps,
  title    = {Characterization of ancient and modern genomes by {SNP} detection
              and phylogenomic and metagenomic analysis using {PALEOMIX}},
  author   = {Schubert, Mikkel and Ermini, Luca and Der Sarkissian, Clio and
              Jónsson, Hákon and Ginolhac, Aurélien and Schaefer, Robert and
              Martin, Michael D and Fernández, Ruth and Kircher, Martin and
              McCue, Molly and Willerslev, Eske and Orlando, Ludovic},
  journal  = {Nature protocols},
  volume   = 9,
  number   = 5,
  pages    = {1056--1082},
  abstract = {Next-generation sequencing technologies have revolutionized the
              field of paleogenomics, allowing the reconstruction of complete
              ancient genomes and their comparison with modern references.
              However, this requires the processing of vast amounts of data and
              involves a large number of steps that use a variety of
              computational tools. Here we present PALEOMIX
              (http://geogenetics.ku.dk/publications/paleomix), a flexible and
              user-friendly pipeline applicable to both modern and ancient
              genomes, which largely automates the in silico analyses behind
              whole-genome resequencing. Starting with next-generation
              sequencing reads, PALEOMIX carries out adapter removal, mapping
              against reference genomes, PCR duplicate removal, characterization
              of and compensation for postmortem damage, SNP calling and
              maximum-likelihood phylogenomic inference, and it profiles the
              metagenomic contents of the samples. As such, PALEOMIX allows for
              a series of potential applications in paleogenomics, comparative
              genomics and metagenomics. Applying the PALEOMIX pipeline to the
              three ancient and seven modern Phytophthora infestans genomes as
              described here takes 5 d using a 16-core server.},
  month    = may,
  year     = 2014,
  url      = {http://dx.doi.org/10.1038/nprot.2014.063},
  doi      = {10.1038/nprot.2014.063},
  pmid     = 24722405,
  issn     = {1754-2189,1750-2799}
}

@article{Yu2020-zw,
  title    = {Paleolithic to Bronze Age Siberians Reveal Connections with First
              Americans and across Eurasia},
  author   = {Yu, He and Spyrou, Maria A and Karapetian, Marina and Shnaider,
              Svetlana and Radzevičiūtė, Rita and Nägele, Kathrin and Neumann,
              Gunnar U and Penske, Sandra and Zech, Jana and Lucas, Mary and
              LeRoux, Petrus and Roberts, Patrick and Pavlenok, Galina and
              Buzhilova, Alexandra and Posth, Cosimo and Jeong, Choongwon and
              Krause, Johannes},
  journal  = {Cell},
  volume   = 181,
  number   = 6,
  pages    = {1232--1245.e20},
  abstract = {Modern humans have inhabited the Lake Baikal region since the
              Upper Paleolithic, though the precise history of its peoples over
              this long time span is still largely unknown. Here, we report
              genome-wide data from 19 Upper Paleolithic to Early Bronze Age
              individuals from this Siberian region. An Upper Paleolithic genome
              shows a direct link with the First Americans by sharing the
              admixed ancestry that gave rise to all non-Arctic Native
              Americans. We also demonstrate the formation of Early Neolithic
              and Bronze Age Baikal populations as the result of prolonged
              admixture throughout the eighth to sixth millennium BP. Moreover,
              we detect genetic interactions with western Eurasian steppe
              populations and reconstruct Yersinia pestis genomes from two Early
              Bronze Age individuals without western Eurasian ancestry. Overall,
              our study demonstrates the most deeply divergent connection
              between Upper Paleolithic Siberians and the First Americans and
              reveals human and pathogen mobility across Eurasia during the
              Bronze Age.},
  month    = jun,
  year     = 2020,
  url      = {http://dx.doi.org/10.1016/j.cell.2020.04.037},
  keywords = {Bronze Age; Native Americans; Neolithic; Siberia; Upper
              Paleolithic; Yersinia pestis; ancient genomics; human history;
              mobility},
  doi      = {10.1016/j.cell.2020.04.037},
  pmid     = 32437661,
  issn     = {0092-8674,1097-4172},
  language = {en}
}

@article{Peltzer2016-ov,
  title    = {{EAGER}: efficient ancient genome reconstruction},
  author   = {Peltzer, Alexander and Jäger, Günter and Herbig, Alexander and
              Seitz, Alexander and Kniep, Christian and Krause, Johannes and
              Nieselt, Kay},
  journal  = {Genome biology},
  volume   = 17,
  number   = 1,
  pages    = {1--14},
  abstract = {The automated reconstruction of genome sequences in ancient genome
              analysis is a multifaceted process.},
  year     = 2016,
  url      = {http://dx.doi.org/10.1186/s13059-016-0918-z},
  doi      = {10.1186/s13059-016-0918-z},
  issn     = {1465-6906,1474-760X}
}

@article{Neuenschwander2023-aj,
  title     = {Mapache: a flexible pipeline to map ancient {DNA}},
  author    = {Neuenschwander, Samuel and Cruz Dávalos, Diana I and Anchieri,
               Lucas and Sousa da Mota, Bárbara and Bozzi, Davide and Rubinacci,
               Simone and Delaneau, Olivier and Rasmussen, Simon and Malaspinas,
               Anna-Sapfo},
  journal   = {Bioinformatics (Oxford, England)},
  publisher = {Oxford University Press (OUP)},
  volume    = 39,
  number    = 2,
  pages     = {btad028},
  abstract  = {SUMMARY: We introduce mapache, a flexible, robust and scalable
               pipeline to map, quantify and impute ancient and present-day DNA
               in a reproducible way. Mapache is implemented in the workflow
               manager Snakemake and is optimized for low-space consumption,
               allowing to efficiently (re)map large datasets-such as reference
               panels and multiple extracts and libraries per sample - to one or
               several genomes. Mapache can easily be customized or combined
               with other Snakemake tools. AVAILABILITY AND IMPLEMENTATION:
               Mapache is freely available on GitHub
               (https://github.com/sneuensc/mapache). An extensive manual is
               provided at https://github.com/sneuensc/mapache/wiki.
               SUPPLEMENTARY INFORMATION: Supplementary data are available at
               Bioinformatics online.},
  month     = feb,
  year      = 2023,
  url       = {https://academic.oup.com/bioinformatics/article-pdf/39/2/btad028/50436112/btad028.pdf},
  doi       = {10.1093/bioinformatics/btad028},
  pmc       = {PMC9901408},
  pmid      = 36637197,
  issn      = {1367-4803,1367-4811},
  language  = {en}
}


@article{Vagene2018-px,
  title    = {Salmonella enterica genomes from victims of a major
              sixteenth-century epidemic in Mexico},
  author   = {Vågene, Åshild J and Herbig, Alexander and Campana, Michael G and
              Robles García, Nelly M and Warinner, Christina and Sabin, Susanna
              and Spyrou, Maria A and Andrades Valtueña, Aida and Huson, Daniel
              and Tuross, Noreen and Bos, Kirsten I and Krause, Johannes},
  journal  = {Nature ecology \& evolution},
  volume   = 2,
  number   = 3,
  pages    = {520--528},
  abstract = {Indigenous populations of the Americas experienced high mortality
              rates during the early contact period as a result of infectious
              diseases, many of which were introduced by Europeans. Most of the
              pathogenic agents that caused these outbreaks remain unknown.
              Through the introduction of a new metagenomic analysis tool called
              MALT, applied here to search for traces of ancient pathogen DNA,
              we were able to identify Salmonella enterica in individuals buried
              in an early contact era epidemic cemetery at Teposcolula-Yucundaa,
              Oaxaca in southern Mexico. This cemetery is linked, based on
              historical and archaeological evidence, to the 1545-1550 CE
              epidemic that affected large parts of Mexico. Locally, this
              epidemic was known as 'cocoliztli', the pathogenic cause of which
              has been debated for more than a century. Here, we present
              genome-wide data from ten individuals for Salmonella enterica
              subsp. enterica serovar Paratyphi C, a bacterial cause of enteric
              fever. We propose that S. Paratyphi C be considered a strong
              candidate for the epidemic population decline during the 1545
              cocoliztli outbreak at Teposcolula-Yucundaa.},
  month    = jan,
  year     = 2018,
  url      = {http://dx.doi.org/10.1038/s41559-017-0446-6},
  doi      = {10.1038/s41559-017-0446-6},
  pmid     = 29335577,
  issn     = {2397-334X},
  language = {en}
}

@article{Herbig2016-rq,
  title    = {{MALT}: Fast alignment and analysis of metagenomic {DNA} sequence
              data applied to the Tyrolean Iceman},
  author   = {Herbig, Alexander and Maixner, Frank and Bos, Kirsten I and Zink,
              Albert and Krause, Johannes and Huson, Daniel H},
  journal  = {bioRxiv},
  pages    = 050559,
  abstract = {Abstract Modern next generation sequencing technologies produce
              vast amounts of data in the context of large-scale metagenomic
              studies, in which complex microbial communities can be
              reconstructed to an unprecedented level of detail. Most prominent
              examples are human microbiome studies that correlate the bacterial
              taxonomic profile with specific physiological conditions or
              diseases.In order to perform these analyses high-throughput
              computational tools are needed that are able to process these data
              within a short time while preserving a high level of sensitivity
              and specificity.Here we present MALT (MEGAN ALignment Tool) a
              program for the ultrafast alignment and analysis of metagenomic
              DNA sequencing data. MALT processes hundreds of millions of
              sequencing reads within only a few hours. In addition to the
              alignment procedure MALT implements a taxonomic binning algorithm
              that is able to specifically assign reads to bacterial species.
              Its tight integration with the interactive metagenomic analysis
              software MEGAN allows for visualization and further analyses of
              results.We demonstrate MALT by its application to the metagenomic
              analysis of two ancient microbiomes from oral cavity and lung
              samples of the 5,300-year-old Tyrolean Iceman. Despite the strong
              environmental background, MALT is able to pick up the weak signal
              of the original microbiomes and identifies multiple species that
              are typical representatives of the respective host environment.},
  month    = apr,
  year     = 2016,
  url      = {https://www.biorxiv.org/content/10.1101/050559v1},
  doi      = {10.1101/050559},
  language = {en}
}

@article{Ewels2016-mv,
  title    = {{MultiQC}: summarize analysis results for multiple tools and
              samples in a single report},
  author   = {Ewels, Philip and Magnusson, Måns and Lundin, Sverker and Käller,
              Max},
  journal  = {Bioinformatics},
  volume   = 32,
  number   = 19,
  pages    = {3047--3048},
  abstract = {MOTIVATION: Fast and accurate quality control is essential for
              studies involving next-generation sequencing data. Whilst numerous
              tools exist to quantify QC metrics, there is no common approach to
              flexibly integrate these across tools and large sample sets.
              Assessing analysis results across an entire project can be time
              consuming and error prone; batch effects and outlier samples can
              easily be missed in the early stages of analysis. RESULTS: We
              present MultiQC, a tool to create a single report visualising
              output from multiple tools across many samples, enabling global
              trends and biases to be quickly identified. MultiQC can plot data
              from many common bioinformatics tools and is built to allow easy
              extension and customization. AVAILABILITY AND IMPLEMENTATION:
              MultiQC is available with an GNU GPLv3 license on GitHub, the
              Python Package Index and Bioconda. Documentation and example
              reports are available at http://multiqc.info CONTACT:
              phil.ewels@scilifelab.se.},
  month    = oct,
  year     = 2016,
  url      = {http://dx.doi.org/10.1093/bioinformatics/btw354},
  doi      = {10.1093/bioinformatics/btw354},
  pmc      = {PMC5039924},
  pmid     = 27312411,
  issn     = {1367-4803,1367-4811},
  language = {en}
}

@article{Borry2024-dz,
  title     = {Facilitating accessible, rapid, and appropriate processing of
               ancient metagenomic data with {AMDirT}},
  author    = {Borry, Maxime and Forsythe, Adrian and Andrades Valtueña, Aida
               and Hübner, Alexander and Ibrahim, Anan and Quagliariello, Andrea
               and White, Anna E and Kocher, Arthur and Vågene‬, Åshild J and
               Bartholdy, Bjørn Peare and Spurīte, Diāna and Ponce-Soto, Gabriel
               Yaxal and Neumann, Gunnar and Huang, I-Ting and Light, Ian and
               Velsko, Irina M and Jackson, Iseult and Frangenberg, Jasmin and
               Serrano, Javier G and Fumey, Julien and Özdoğan, Kadir T and
               Blevins, Kelly E and Daly, Kevin G and Lopopolo, Maria and
               Moraitou, Markella and Michel, Megan and van Os, Meriam and
               Bravo-Lopez, Miriam J and Sarhan, Mohamed S and Dagtas, Nihan D
               and Oskolkov, Nikolay and Smith, Olivia S and Lebrasseur, Ophélie
               and Rozwalak, Piotr and Eisenhofer, Raphael and Wasef, Sally and
               Ramachandran, Shreya L and Vanghi, Valentina and Warinner,
               Christina and Fellows Yates, James A},
  journal   = {F1000Research},
  publisher = {F1000 Research Ltd},
  volume    = 12,
  number    = 926,
  pages     = 926,
  abstract  = {Background Access to sample-level metadata is important when
               selecting public metagenomic sequencing datasets for reuse in new
               biological analyses. The Standards, Precautions, and Advances in
               Ancient Metagenomics community (SPAAM,
               https://spaam-community.org) has previously published
               AncientMetagenomeDir, a collection of curated and standardised
               sample metadata tables for metagenomic and microbial genome
               datasets generated from ancient samples. However, while
               sample-level information is useful for identifying relevant
               samples for inclusion in new projects, Next Generation Sequencing
               (NGS) library construction and sequencing metadata are also
               essential for appropriately reprocessing ancient metagenomic
               data. Currently, recovering information for downloading and
               preparing such data is difficult when laboratory and
               bioinformatic metadata is heterogeneously recorded in prose-based
               publications. Methods Through a series of community-based
               hackathon events, AncientMetagenomeDir was updated to provide
               standardised library-level metadata of existing and new ancient
               metagenomic samples. In tandem, the companion tool 'AMDirT' was
               developed to facilitate rapid data filtering and downloading of
               ancient metagenomic data, as well as improving automated metadata
               curation and validation for AncientMetagenomeDir. Results
               AncientMetagenomeDir was extended to include standardised
               metadata of over 6000 ancient metagenomic libraries. The
               companion tool 'AMDirT' provides both graphical- and command-line
               interface based access to such metadata for users from a wide
               range of computational backgrounds. We also report on errors with
               metadata reporting that appear to commonly occur during data
               upload and provide suggestions on how to improve the quality of
               data sharing by the community. Conclusions Together, both
               standardised metadata reporting and tooling will help towards
               easier incorporation and reuse of public ancient metagenomic
               datasets into future analyses.},
  month     = may,
  year      = 2024,
  url       = {https://f1000research.com/articles/12-926/pdf},
  keywords  = {
               metagenomics,environmental,palaeogenomics,aDNA,microbiome,metadata,microbial,FAIR
               data},
  doi       = {10.12688/f1000research.134798.2},
  issn      = {2046-1402},
  language  = {en}
}
@article{Poplin2018-yq,
  title    = {Scaling accurate genetic variant discovery to tens of thousands of
              samples},
  author   = {Poplin, Ryan and Ruano-Rubio, Valentin and DePristo, Mark A and
              Fennell, Tim J and Carneiro, Mauricio O and Van der Auwera,
              Geraldine A and Kling, David E and Gauthier, Laura D and
              Levy-Moonshine, Ami and Roazen, David and Shakir, Khalid and
              Thibault, Joel and Chandran, Sheila and Whelan, Chris and Lek,
              Monkol and Gabriel, Stacey and Daly, Mark J and Neale, Ben and
              MacArthur, Daniel G and Banks, Eric},
  journal  = {bioRxiv},
  pages    = 201178,
  abstract = {Abstract Comprehensive disease gene discovery in both common and
              rare diseases will require the efficient and accurate detection of
              all classes of genetic variation across tens to hundreds of
              thousands of human samples. We describe here a novel
              assembly-based approach to variant calling, the GATK
              HaplotypeCaller (HC) and Reference Confidence Model (RCM), that
              determines genotype likelihoods independently per-sample but
              performs joint calling across all samples within a project
              simultaneously. We show by calling over 90,000 samples from the
              Exome Aggregation Consortium (ExAC) that, in contrast to other
              algorithms, the HC-RCM scales efficiently to very large sample
              sizes without loss in accuracy; and that the accuracy of indel
              variant calling is superior in comparison to other algorithms.
              More importantly, the HC-RCM produces a fully squared-off matrix
              of genotypes across all samples at every genomic position being
              investigated. The HC-RCM is a novel, scalable, assembly-based
              algorithm with abundant applications for population genetics and
              clinical studies.},
  month    = jul,
  year     = 2018,
  url      = {https://www.biorxiv.org/content/10.1101/201178v3},
  doi      = {10.1101/201178},
  language = {en}
}
@article{Danecek2021-gj,
  title     = {Twelve years of {SAMtools} and {BCFtools}},
  author    = {Danecek, Petr and Bonfield, James K and Liddle, Jennifer and
               Marshall, John and Ohan, Valeriu and Pollard, Martin O and
               Whitwham, Andrew and Keane, Thomas and McCarthy, Shane A and
               Davies, Robert M and Li, Heng},
  journal   = {GigaScience},
  publisher = {Oxford Academic},
  volume    = 10,
  number    = 2,
  abstract  = {AbstractBackground. SAMtools and BCFtools are widely used
               programs for processing and analysing high-throughput sequencing
               data. They include tools for file for},
  month     = jan,
  year      = 2021,
  url       = {https://academic.oup.com/gigascience/article-pdf/10/2/giab008/36332246/giab008.pdf},
  doi       = {10.1093/gigascience/giab008}
}
@article{Quinlan2010-lf,
  title    = {{BEDTools}: a flexible suite of utilities for comparing genomic
              features},
  author   = {Quinlan, Aaron R and Hall, Ira M},
  journal  = {Bioinformatics},
  volume   = 26,
  number   = 6,
  pages    = {841--842},
  abstract = {MOTIVATION: Testing for correlations between different sets of
              genomic features is a fundamental task in genomics research.
              However, searching for overlaps between features with existing
              web-based methods is complicated by the massive datasets that are
              routinely produced with current sequencing technologies. Fast and
              flexible tools are therefore required to ask complex questions of
              these data in an efficient manner. RESULTS: This article
              introduces a new software suite for the comparison, manipulation
              and annotation of genomic features in Browser Extensible Data
              (BED) and General Feature Format (GFF) format. BEDTools also
              supports the comparison of sequence alignments in BAM format to
              both BED and GFF features. The tools are extremely efficient and
              allow the user to compare large datasets (e.g. next-generation
              sequencing data) with both public and custom genome annotation
              tracks. BEDTools can be combined with one another as well as with
              standard UNIX commands, thus facilitating routine genomics tasks
              as well as pipelines that can quickly answer intricate questions
              of large genomic datasets. AVAILABILITY AND IMPLEMENTATION:
              BEDTools was written in C++. Source code and a comprehensive user
              manual are freely available at http://code.google.com/p/bedtools
              CONTACT: aaronquinlan@gmail.com; imh4y@virginia.edu SUPPLEMENTARY
              INFORMATION: Supplementary data are available at Bioinformatics
              online.},
  month    = mar,
  year     = 2010,
  url      = {http://dx.doi.org/10.1093/bioinformatics/btq033},
  doi      = {10.1093/bioinformatics/btq033},
  pmc      = {PMC2832824},
  pmid     = 20110278,
  issn     = {1367-4803,1367-4811},
  language = {en}
}
@article{Neukamm2021-ul,
  title     = {{DamageProfiler}: Fast damage pattern calculation for ancient
               {DNA}},
  author    = {Neukamm, Judith and Peltzer, Alexander and Nieselt, Kay},
  journal   = {Bioinformatics},
  publisher = {Oxford University Press},
  volume    = 37,
  number    = 20,
  pages     = {3652–3653},
  abstract  = {MOTIVATION: In ancient DNA research, the authentication of
               ancient samples based on specific features remains a crucial step
               in data analysis. Because of this central importance, researchers
               lacking deeper programming knowledge should be able to run a
               basic damage authentication analysis. Such software should be
               user-friendly and easy to integrate into an analysis pipeline.
               RESULTS: DamageProfiler is a Java based, stand-alone software to
               determine damage patterns in ancient DNA. The results are
               provided in various file formats and plots for further
               processing. DamageProfiler has an intuitive graphical as well as
               command line interface that allows the tool to be easily embedded
               into an analysis pipeline. AVAILABILITY: All of the source code
               is freely available on GitHub
               (https://github.com/Integrative-Transcriptomics/DamageProfiler).
               SUPPLEMENTARY INFORMATION: Supplementary data are available at
               Bioinformatics online.},
  month     = apr,
  year      = 2021,
  url       = {http://dx.doi.org/10.1093/bioinformatics/btab190},
  doi       = {10.1093/bioinformatics/btab190},
  pmid      = 33890614,
  issn      = {1367-4803,1367-4811},
  language  = {en}
}
@article{Di_Tommaso2017-xu,
  title    = {Nextflow enables reproducible computational workflows},
  author   = {Di Tommaso, Paolo and Chatzou, Maria and Floden, Evan W and Barja,
              Pablo Prieto and Palumbo, Emilio and Notredame, Cedric},
  journal  = {Nature biotechnology},
  volume   = 35,
  number   = 4,
  pages    = {316--319},
  month    = apr,
  year     = 2017,
  url      = {http://dx.doi.org/10.1038/nbt.3820},
  doi      = {10.1038/nbt.3820},
  pmid     = 28398311,
  issn     = {1087-0156,1546-1696},
  language = {en}
}
@article{Molder2021-et,
  title    = {Sustainable data analysis with Snakemake},
  author   = {Mölder, Felix and Jablonski, Kim Philipp and Letcher, Brice and
              Hall, Michael B and Tomkins-Tinch, Christopher H and Sochat,
              Vanessa and Forster, Jan and Lee, Soohyun and Twardziok, Sven O
              and Kanitz, Alexander and Wilm, Andreas and Holtgrewe, Manuel and
              Rahmann, Sven and Nahnsen, Sven and Köster, Johannes},
  journal  = {F1000Research},
  volume   = 10,
  pages    = 33,
  abstract = {Data analysis often entails a multitude of heterogeneous steps,
              from the application of various command line tools to the usage of
              scripting languages like R or Python for the generation of plots
              and tables. It is widely recognized that data analyses should
              ideally be conducted in a reproducible way. Reproducibility
              enables technical validation and regeneration of results on the
              original or even new data. However, reproducibility alone is by no
              means sufficient to deliver an analysis that is of lasting impact
              (i.e., sustainable) for the field, or even just one research
              group. We postulate that it is equally important to ensure
              adaptability and transparency. The former describes the ability to
              modify the analysis to answer extended or slightly different
              research questions. The latter describes the ability to understand
              the analysis in order to judge whether it is not only technically,
              but methodologically valid. Here, we analyze the properties needed
              for a data analysis to become reproducible, adaptable, and
              transparent. We show how the popular workflow management system
              Snakemake can be used to guarantee this, and how it enables an
              ergonomic, combined, unified representation of all steps involved
              in data analysis, ranging from raw data processing, to quality
              control and fine-grained, interactive exploration and plotting of
              final results.},
  month    = jan,
  year     = 2021,
  url      = {http://dx.doi.org/10.12688/f1000research.29032.2},
  keywords = {adaptability; data analysis; reproducibility; scalability;
              sustainability; transparency; workflow management},
  doi      = {10.12688/f1000research.29032.2},
  pmc      = {PMC8114187},
  pmid     = 34035898,
  issn     = {2046-1402},
  language = {en}
}
@article{Wood2019-mf,
  title    = {Improved metagenomic analysis with Kraken 2},
  author   = {Wood, Derrick E and Lu, Jennifer and Langmead, Ben},
  journal  = {Genome biology},
  volume   = 20,
  number   = 1,
  pages    = 257,
  abstract = {Although Kraken's k-mer-based approach provides a fast taxonomic
              classification of metagenomic sequence data, its large memory
              requirements can be limiting for some applications. Kraken 2
              improves upon Kraken 1 by reducing memory usage by 85\%, allowing
              greater amounts of reference genomic data to be used, while
              maintaining high accuracy and increasing speed fivefold. Kraken 2
              also introduces a translated search mode, providing increased
              sensitivity in viral metagenomics analysis.},
  month    = nov,
  year     = 2019,
  url      = {http://dx.doi.org/10.1186/s13059-019-1891-0},
  keywords = {Alignment-free methods; Metagenomics; Metagenomics classification;
              Microbiome; Minimizers; Probabilistic data structures},
  doi      = {10.1186/s13059-019-1891-0},
  pmid     = 31779668,
  issn     = {1474-760X,1474-7596},
  language = {en}
}
@article{Breitwieser2018-xg,
  title     = {{KrakenUniq}: confident and fast metagenomics classification
               using unique k-mer counts},
  author    = {Breitwieser, F P and Baker, D N and Salzberg, S L},
  journal   = {Genome biology},
  publisher = {Springer Science and Business Media LLC},
  volume    = 19,
  number    = 1,
  pages     = 198,
  abstract  = {False-positive identifications are a significant problem in
               metagenomics classification. We present KrakenUniq, a novel
               metagenomics classifier that combines the fast k-mer-based
               classification of Kraken with an efficient algorithm for
               assessing the coverage of unique k-mers found in each species in
               a dataset. On various test datasets, KrakenUniq gives better
               recall and precision than other methods and effectively
               classifies and distinguishes pathogens with low abundance from
               false positives in infectious disease samples. By using the
               probabilistic cardinality estimator HyperLogLog, KrakenUniq runs
               as fast as Kraken and requires little additional memory.
               KrakenUniq is freely available at
               https://github.com/fbreitwieser/krakenuniq .},
  month     = nov,
  year      = 2018,
  url       = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1568-0},
  keywords  = {Infectious disease diagnosis; Metagenomics; Metagenomics
               classification; Microbiome; Pathogen detection},
  doi       = {10.1186/s13059-018-1568-0},
  pmc       = {PMC6238331},
  pmid      = 30445993,
  issn      = {1474-7596,1474-760X},
  language  = {en}
}

@article{Chen2018-vg,
  title     = {fastp: an ultra-fast all-in-one {FASTQ} preprocessor},
  author    = {Chen, Shifu and Zhou, Yanqing and Chen, Yaru and Gu, Jia},
  journal   = {Bioinformatics},
  publisher = {Oxford University Press},
  volume    = 34,
  number    = 17,
  pages     = {i884--i890},
  abstract  = {Quality control and preprocessing of FASTQ files are essential to
               providing clean data for downstream analysis. Traditionally, a
               different tool is used for each operation, such as quality
               control, adapter trimming and quality filtering. These tools are
               often insufficiently fast as most are developed using high-level
               programming languages (e.g. Python and Java) and provide limited
               multi-threading support. Reading and loading data multiple times
               also renders preprocessing slow and I/O inefficient.We developed
               fastp as an ultra-fast FASTQ preprocessor with useful quality
               control and data-filtering features. It can perform quality
               control, adapter trimming, quality filtering, per-read quality
               pruning and many other operations with a single scan of the FASTQ
               data. This tool is developed in C++ and has multi-threading
               support. Based on our evaluation, fastp is 2–5 times faster than
               other FASTQ preprocessing tools such as Trimmomatic or Cutadapt
               despite performing far more operations than similar tools.The
               open-source code and corresponding instructions are available at
               https://github.com/OpenGene/fastp.},
  month     = sep,
  year      = 2018,
  url       = {https://academic.oup.com/bioinformatics/article/34/17/i884/5093234},
  doi       = {10.1093/bioinformatics/bty560},
  issn      = {1367-4803}
}

@article{Schubert2016-qv,
  title    = {{AdapterRemoval} {v2}: rapid adapter trimming, identification, and
              read merging},
  author   = {Schubert, Mikkel and Lindgreen, Stinus and Orlando, Ludovic},
  journal  = {BMC research notes},
  volume   = 9,
  pages    = 88,
  abstract = {BACKGROUND: As high-throughput sequencing platforms produce longer
              and longer reads, sequences generated from short inserts, such as
              those obtained from fossil and degraded material, are increasingly
              expected to contain adapter sequences. Efficient adapter trimming
              algorithms are also needed to process the growing amount of data
              generated per sequencing run. FINDINGS: We introduce
              AdapterRemoval v2, a major revision of AdapterRemoval v1, which
              introduces (i) striking improvements in throughput, through the
              use of single instruction, multiple data (SIMD; SSE1 and SSE2)
              instructions and multi-threading support, (ii) the ability to
              handle datasets containing reads or read-pairs with different
              adapters or adapter pairs, (iii) simultaneous demultiplexing and
              adapter trimming, (iv) the ability to reconstruct adapter
              sequences from paired-end reads for poorly documented data sets,
              and (v) native gzip and bzip2 support. CONCLUSIONS: We show that
              AdapterRemoval v2 compares favorably with existing tools, while
              offering superior throughput to most alternatives examined here,
              both for single and multi-threaded operations.},
  month    = feb,
  year     = 2016,
  url      = {http://dx.doi.org/10.1186/s13104-016-1900-2},
  doi      = {10.1186/s13104-016-1900-2},
  pmc      = {PMC4751634},
  pmid     = 26868221,
  issn     = {1756-0500},
  language = {en}
}

@article{Kim2016-qc,
  title    = {Centrifuge: rapid and sensitive classification of metagenomic
              sequences},
  author   = {Kim, Daehwan and Song, Li and Breitwieser, Florian P and Salzberg,
              Steven L},
  journal  = {Genome research},
  volume   = 26,
  number   = 12,
  pages    = {1721--1729},
  abstract = {Centrifuge is a novel microbial classification engine that enables
              rapid, accurate, and sensitive labeling of reads and
              quantification of species on desktop computers. The system uses an
              indexing scheme based on the Burrows-Wheeler transform (BWT) and
              the Ferragina-Manzini (FM) index, optimized specifically for the
              metagenomic classification problem. Centrifuge requires a
              relatively small index (4.2 GB for 4078 bacterial and 200 archaeal
              genomes) and classifies sequences at very high speed, allowing it
              to process the millions of reads from a typical high-throughput
              DNA sequencing run within a few minutes. Together, these advances
              enable timely and accurate analysis of large metagenomics data
              sets on conventional desktop computers. Because of its
              space-optimized indexing schemes, Centrifuge also makes it
              possible to index the entire NCBI nonredundant nucleotide sequence
              database (a total of 109 billion bases) with an index size of 69
              GB, in contrast to k-mer-based indexing schemes, which require far
              more extensive space.},
  month    = dec,
  year     = 2016,
  url      = {http://dx.doi.org/10.1101/gr.210641.116},
  doi      = {10.1101/gr.210641.116},
  pmc      = {PMC5131823},
  pmid     = 27852649,
  issn     = {1088-9051,1549-5469},
  language = {en}
}
@article{Li2015-lj,
  title    = {{MEGAHIT}: an ultra-fast single-node solution for large and
              complex metagenomics assembly via succinct de Bruijn graph},
  author   = {Li, Dinghua and Liu, Chi-Man and Luo, Ruibang and Sadakane,
              Kunihiko and Lam, Tak-Wah},
  journal  = {Bioinformatics},
  volume   = 31,
  number   = 10,
  pages    = {1674--1676},
  abstract = {MEGAHIT is a NGS de novo assembler for assembling large and
              complex metagenomics data in a time- and cost-efficient manner. It
              finished assembling a soil metagenomics dataset with 252 Gbps in
              44.1 and 99.6 h on a single computing node with and without a
              graphics processing unit, respectively. MEGAHIT assembles the data
              as a whole, i.e. no pre-processing like partitioning and
              normalization was needed. When compared with previous methods on
              assembling the soil data, MEGAHIT generated a three-time larger
              assembly, with longer contig N50 and average contig length;
              furthermore, 55.8\% of the reads were aligned to the assembly,
              giving a fourfold improvement.},
  month    = may,
  year     = 2015,
  url      = {http://dx.doi.org/10.1093/bioinformatics/btv033},
  doi      = {10.1093/bioinformatics/btv033},
  pmid     = 25609793,
  issn     = {1367-4803,1367-4811},
  language = {en}
}
@article{Bankevich2012-jl,
  title    = {{SPAdes}: a new genome assembly algorithm and its applications to
              single-cell sequencing},
  author   = {Bankevich, Anton and Nurk, Sergey and Antipov, Dmitry and
              Gurevich, Alexey A and Dvorkin, Mikhail and Kulikov, Alexander S
              and Lesin, Valery M and Nikolenko, Sergey I and Pham, Son and
              Prjibelski, Andrey D and Pyshkin, Alexey V and Sirotkin, Alexander
              V and Vyahhi, Nikolay and Tesler, Glenn and Alekseyev, Max A and
              Pevzner, Pavel A},
  journal  = {Journal of computational biology: a journal of computational
              molecular cell biology},
  volume   = 19,
  number   = 5,
  pages    = {455--477},
  abstract = {The lion's share of bacteria in various environments cannot be
              cloned in the laboratory and thus cannot be sequenced using
              existing technologies. A major goal of single-cell genomics is to
              complement gene-centric metagenomic data with whole-genome
              assemblies of uncultivated organisms. Assembly of single-cell data
              is challenging because of highly non-uniform read coverage as well
              as elevated levels of sequencing errors and chimeric reads. We
              describe SPAdes, a new assembler for both single-cell and standard
              (multicell) assembly, and demonstrate that it improves on the
              recently released E+V-SC assembler (specialized for single-cell
              data) and on popular assemblers Velvet and SoapDeNovo (for
              multicell data). SPAdes generates single-cell assemblies,
              providing information about genomes of uncultivatable bacteria
              that vastly exceeds what may be obtained via traditional
              metagenomics studies. SPAdes is available online (
              http://bioinf.spbau.ru/spades ). It is distributed as open source
              software.},
  month    = may,
  year     = 2012,
  url      = {http://dx.doi.org/10.1089/cmb.2012.0021},
  doi      = {10.1089/cmb.2012.0021},
  pmc      = {PMC3342519},
  pmid     = 22506599,
  issn     = {1066-5277,1557-8666}
}
@article{Nurk2017-xh,
  title    = {{metaSPAdes}: a new versatile metagenomic assembler},
  author   = {Nurk, Sergey and Meleshko, Dmitry and Korobeynikov, Anton and
              Pevzner, Pavel A},
  journal  = {Genome research},
  volume   = 27,
  number   = 5,
  pages    = {824--834},
  abstract = {While metagenomics has emerged as a technology of choice for
              analyzing bacterial populations, the assembly of metagenomic data
              remains challenging, thus stifling biological discoveries.
              Moreover, recent studies revealed that complex bacterial
              populations may be composed from dozens of related strains, thus
              further amplifying the challenge of metagenomic assembly.
              metaSPAdes addresses various challenges of metagenomic assembly by
              capitalizing on computational ideas that proved to be useful in
              assemblies of single cells and highly polymorphic diploid genomes.
              We benchmark metaSPAdes against other state-of-the-art metagenome
              assemblers and demonstrate that it results in high-quality
              assemblies across diverse data sets.},
  month    = may,
  year     = 2017,
  url      = {http://dx.doi.org/10.1101/gr.213959.116},
  doi      = {10.1101/gr.213959.116},
  pmc      = {PMC5411777},
  pmid     = 28298430,
  issn     = {1088-9051,1549-5469},
  language = {en}
}
@article{Hyatt2010-yv,
  title    = {Prodigal: prokaryotic gene recognition and translation initiation
              site identification},
  author   = {Hyatt, Doug and Chen, Gwo-Liang and Locascio, Philip F and Land,
              Miriam L and Larimer, Frank W and Hauser, Loren J},
  journal  = {BMC bioinformatics},
  volume   = 11,
  pages    = 119,
  abstract = {BACKGROUND: The quality of automated gene prediction in microbial
              organisms has improved steadily over the past decade, but there is
              still room for improvement. Increasing the number of correct
              identifications, both of genes and of the translation initiation
              sites for each gene, and reducing the overall number of false
              positives, are all desirable goals. RESULTS: With our years of
              experience in manually curating genomes for the Joint Genome
              Institute, we developed a new gene prediction algorithm called
              Prodigal (PROkaryotic DYnamic programming Gene-finding ALgorithm).
              With Prodigal, we focused specifically on the three goals of
              improved gene structure prediction, improved translation
              initiation site recognition, and reduced false positives. We
              compared the results of Prodigal to existing gene-finding methods
              to demonstrate that it met each of these objectives. CONCLUSION:
              We built a fast, lightweight, open source gene prediction program
              called Prodigal http://compbio.ornl.gov/prodigal/. Prodigal
              achieved good results compared to existing methods, and we believe
              it will be a valuable asset to automated microbial annotation
              pipelines.},
  month    = mar,
  year     = 2010,
  url      = {http://dx.doi.org/10.1186/1471-2105-11-119},
  doi      = {10.1186/1471-2105-11-119},
  pmc      = {PMC2848648},
  pmid     = 20211023,
  issn     = {1471-2105},
  language = {en}
}
@article{Gurevich2013-iq,
  title     = {{QUAST}: quality assessment tool for genome assemblies},
  author    = {Gurevich, Alexey and Saveliev, Vladislav and Vyahhi, Nikolay and
               Tesler, Glenn},
  journal   = {Bioinformatics (Oxford, England)},
  publisher = {Oxford University Press (OUP)},
  volume    = 29,
  number    = 8,
  pages     = {1072--1075},
  abstract  = {SUMMARY: Limitations of genome sequencing techniques have led to
               dozens of assembly algorithms, none of which is perfect. A number
               of methods for comparing assemblers have been developed, but none
               is yet a recognized benchmark. Further, most existing methods for
               comparing assemblies are only applicable to new assemblies of
               finished genomes; the problem of evaluating assemblies of
               previously unsequenced species has not been adequately
               considered. Here, we present QUAST-a quality assessment tool for
               evaluating and comparing genome assemblies. This tool improves on
               leading assembly comparison software with new ideas and quality
               metrics. QUAST can evaluate assemblies both with a reference
               genome, as well as without a reference. QUAST produces many
               reports, summary tables and plots to help scientists in their
               research and in their publications. In this study, we used QUAST
               to compare several genome assemblers on three datasets. QUAST
               tables and plots for all of them are available in the
               Supplementary Material, and interactive versions of these reports
               are on the QUAST website. AVAILABILITY:
               http://bioinf.spbau.ru/quast . SUPPLEMENTARY INFORMATION:
               Supplementary data are available at Bioinformatics online.},
  month     = apr,
  year      = 2013,
  url       = {https://pubmed.ncbi.nlm.nih.gov/23422339/},
  doi       = {10.1093/bioinformatics/btt086},
  pmc       = {PMC3624806},
  pmid      = 23422339,
  issn      = {1367-4803,1367-4811},
  language  = {en}
}
@article{Borry2021-lt,
  title     = {{PyDamage}: automated ancient damage identification and
               estimation for contigs in ancient {DNA} de novo assembly},
  author    = {Borry, Maxime and Hübner, Alexander and Rohrlach, Adam B and
               Warinner, Christina},
  journal   = {PeerJ},
  publisher = {PeerJ Inc.},
  volume    = 9,
  pages     = {e11845},
  abstract  = {DNA de novo assembly can be used to reconstruct longer stretches
               of DNA (contigs), including genes and even genomes, from short
               DNA sequencing reads. Applying this technique to metagenomic data
               derived from archaeological remains, such as paleofeces and
               dental calculus, we can investigate past microbiome functional
               diversity that may be absent or underrepresented in the modern
               microbiome gene catalogue. However, compared to modern samples,
               ancient samples are often burdened with environmental
               contamination, resulting in metagenomic datasets that represent
               mixtures of ancient and modern DNA. The ability to rapidly and
               reliably establish the authenticity and integrity of ancient
               samples is essential for ancient DNA studies, and the ability to
               distinguish between ancient and modern sequences is particularly
               important for ancient microbiome studies. Characteristic patterns
               of ancient DNA damage, namely DNA fragmentation and cytosine
               deamination (observed as C-to-T transitions) are typically used
               to authenticate ancient samples and sequences, but existing tools
               for inspecting and filtering aDNA damage either compute it at the
               read level, which leads to high data loss and lower quality when
               used in combination with de novo assembly, or require manual
               inspection, which is impractical for ancient assemblies that
               typically contain tens to hundreds of thousands of contigs. To
               address these challenges, we designed PyDamage, a robust,
               automated approach for aDNA damage estimation and authentication
               of de novo assembled aDNA. PyDamage uses a likelihood ratio based
               approach to discriminate between truly ancient contigs and
               contigs originating from modern contamination. We test PyDamage
               on both on simulated aDNA data and archaeological paleofeces, and
               we demonstrate its ability to reliably and automatically identify
               contigs bearing DNA damage characteristic of aDNA. Coupled with
               aDNA de novo assembly, Pydamage opens up new doors to explore
               functional diversity in ancient metagenomic datasets.},
  month     = jul,
  year      = 2021,
  url       = {https://peerj.com/articles/11845/},
  keywords  = {metagenomics; aDNA; ancient DNA; assembly; damage; de novo;
               automated},
  doi       = {10.7717/peerj.11845},
  issn      = {2167-8359},
  language  = {en}
}
@article{Garrison2012-pv,
  title         = {Haplotype-based variant detection from short-read sequencing},
  author        = {Garrison, Erik and Marth, Gabor},
  journal       = {arXiv [q-bio.GN]},
  abstract      = {The direct detection of haplotypes from short-read DNA
                   sequencing data requires changes to existing small-variant
                   detection methods. Here, we develop a Bayesian statistical
                   framework which is capable of modeling multiallelic loci in
                   sets of individuals with non-uniform copy number. We then
                   describe our implementation of this framework in a
                   haplotype-based variant detector, FreeBayes.},
  month         = jul,
  year          = 2012,
  url           = {http://arxiv.org/abs/1207.3907},
  archiveprefix = {arXiv},
  primaryclass  = {q-bio.GN},
  eprint        = {1207.3907}
}
@article{Kang2019-ld,
  title     = {{MetaBAT} 2: an adaptive binning algorithm for robust and
               efficient genome reconstruction from metagenome assemblies},
  author    = {Kang, Dongwan D and Li, Feng and Kirton, Edward and Thomas,
               Ashleigh and Egan, Rob and An, Hong and Wang, Zhong},
  journal   = {PeerJ},
  publisher = {PeerJ},
  volume    = 7,
  number    = {e7359},
  pages     = {e7359},
  abstract  = {We previously reported on MetaBAT, an automated metagenome
               binning software tool to reconstruct single genomes from
               microbial communities for subsequent analyses of uncultivated
               microbial species. MetaBAT has become one of the most popular
               binning tools largely due to its computational efficiency and
               ease of use, especially in binning experiments with a large
               number of samples and a large assembly. MetaBAT requires users to
               choose parameters to fine-tune its sensitivity and specificity.
               If those parameters are not chosen properly, binning accuracy can
               suffer, especially on assemblies of poor quality. Here, we
               developed MetaBAT 2 to overcome this problem. MetaBAT 2 uses a
               new adaptive binning algorithm to eliminate manual parameter
               tuning. We also performed extensive software engineering
               optimization to increase both computational and memory
               efficiency. Comparing MetaBAT 2 to alternative software tools on
               over 100 real world metagenome assemblies shows superior accuracy
               and computing speed. Binning a typical metagenome assembly takes
               only a few minutes on a single commodity workstation. We
               therefore recommend the community adopts MetaBAT 2 for their
               metagenome binning experiments. MetaBAT 2 is open source software
               and available at https://bitbucket.org/berkeleylab/metabat.},
  month     = jul,
  year      = 2019,
  url       = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6662567/},
  keywords  = {Clustering; Metagenome binning; Metagenomics},
  doi       = {10.7717/peerj.7359},
  pmc       = {PMC6662567},
  pmid      = 31388474,
  issn      = {2167-8359},
  language  = {en}
}

@article{Wu2015-bz,
  title     = {{MaxBin} 2.0: an automated binning algorithm to recover genomes
               from multiple metagenomic datasets},
  author    = {Wu, Yu-Wei and Simmons, Blake A and Singer, Steven W},
  journal   = {Bioinformatics},
  publisher = {Oxford Academic},
  volume    = 32,
  number    = 4,
  pages     = {605--607},
  abstract  = {Abstract. Summary: The recovery of genomes from metagenomic
               datasets is a critical step to defining the functional roles of
               the underlying uncultivated populati},
  month     = oct,
  year      = 2015,
  url       = {https://academic.oup.com/bioinformatics/article/32/4/605/1744462},
  doi       = {10.1093/bioinformatics/btv638},
  issn      = {1367-4803},
  language  = {en}
}
@article{Alneberg2014-mc,
  title    = {Binning metagenomic contigs by coverage and composition},
  author   = {Alneberg, Johannes and Bjarnason, Brynjar Smári and de Bruijn, Ino
              and Schirmer, Melanie and Quick, Joshua and Ijaz, Umer Z and
              Lahti, Leo and Loman, Nicholas J and Andersson, Anders F and
              Quince, Christopher},
  journal  = {Nature methods},
  volume   = 11,
  number   = 11,
  pages    = {1144--1146},
  abstract = {Shotgun sequencing enables the reconstruction of genomes from
              complex microbial communities, but because assembly does not
              reconstruct entire genomes, it is necessary to bin genome
              fragments. Here we present CONCOCT, a new algorithm that combines
              sequence composition and coverage across multiple samples, to
              automatically cluster contigs into genomes. We demonstrate high
              recall and precision on artificial as well as real human gut
              metagenome data sets.},
  month    = nov,
  year     = 2014,
  url      = {http://dx.doi.org/10.1038/nmeth.3103},
  doi      = {10.1038/nmeth.3103},
  pmid     = 25218180,
  issn     = {1548-7091,1548-7105},
  language = {en}
}
@article{Sieber2018-jt,
  title    = {Recovery of genomes from metagenomes via a dereplication,
              aggregation and scoring strategy},
  author   = {Sieber, Christian M K and Probst, Alexander J and Sharrar, Allison
              and Thomas, Brian C and Hess, Matthias and Tringe, Susannah G and
              Banfield, Jillian F},
  journal  = {Nature microbiology},
  volume   = 3,
  number   = 7,
  pages    = {836--843},
  abstract = {Microbial communities are critical to ecosystem function. A key
              objective of metagenomic studies is to analyse organism-specific
              metabolic pathways and reconstruct community interaction networks.
              This requires accurate assignment of assembled genome fragments to
              genomes. Existing binning methods often fail to reconstruct a
              reasonable number of genomes and report many bins of low quality
              and completeness. Furthermore, the performance of existing
              algorithms varies between samples and biotopes. Here, we present a
              dereplication, aggregation and scoring strategy, DAS Tool, that
              combines the strengths of a flexible set of established binning
              algorithms. DAS Tool applied to a constructed community generated
              more accurate bins than any automated method. Indeed, when applied
              to environmental and host-associated samples of different
              complexity, DAS Tool recovered substantially more near-complete
              genomes, including previously unreported lineages, than any single
              binning method alone. The ability to reconstruct many
              near-complete genomes from metagenomics data will greatly advance
              genome-centric analyses of ecosystems.},
  month    = jul,
  year     = 2018,
  url      = {http://dx.doi.org/10.1038/s41564-018-0171-1},
  doi      = {10.1038/s41564-018-0171-1},
  pmc      = {PMC6786971},
  pmid     = 29807988,
  issn     = {2058-5276},
  language = {en}
}
@article{Seemann2014-ee,
  title    = {Prokka: rapid prokaryotic genome annotation},
  author   = {Seemann, Torsten},
  journal  = {Bioinformatics},
  volume   = 30,
  number   = 14,
  pages    = {2068--2069},
  abstract = {UNLABELLED: The multiplex capability and high yield of current day
              DNA-sequencing instruments has made bacterial whole genome
              sequencing a routine affair. The subsequent de novo assembly of
              reads into contigs has been well addressed. The final step of
              annotating all relevant genomic features on those contigs can be
              achieved slowly using existing web- and email-based systems, but
              these are not applicable for sensitive data or integrating into
              computational pipelines. Here we introduce Prokka, a command line
              software tool to fully annotate a draft bacterial genome in about
              10 min on a typical desktop computer. It produces
              standards-compliant output files for further analysis or viewing
              in genome browsers. AVAILABILITY AND IMPLEMENTATION: Prokka is
              implemented in Perl and is freely available under an open source
              GPLv2 license from http://vicbioinformatics.com/.},
  month    = jul,
  year     = 2014,
  url      = {http://dx.doi.org/10.1093/bioinformatics/btu153},
  doi      = {10.1093/bioinformatics/btu153},
  pmid     = 24642063,
  issn     = {1367-4803,1367-4811},
  language = {en}
}
@article{von-Meijenfeldt2019-qe,
  title     = {Robust taxonomic classification of uncharted microbial sequences
               and bins with {CAT} and {BAT}},
  author    = {von Meijenfeldt, F A Bastiaan and Arkhipova, Ksenia and Cambuy,
               Diego D and Coutinho, Felipe H and Dutilh, Bas E},
  journal   = {Genome biology},
  publisher = {Springer Science and Business Media LLC},
  volume    = 20,
  number    = 1,
  pages     = 217,
  abstract  = {Current-day metagenomics analyses increasingly involve de novo
               taxonomic classification of long DNA sequences and
               metagenome-assembled genomes. Here, we show that the conventional
               best-hit approach often leads to classifications that are too
               specific, especially when the sequences represent novel deep
               lineages. We present a classification method that integrates
               multiple signals to classify sequences (Contig Annotation Tool,
               CAT) and metagenome-assembled genomes (Bin Annotation Tool, BAT).
               Classifications are automatically made at low taxonomic ranks if
               closely related organisms are present in the reference database
               and at higher ranks otherwise. The result is a high
               classification precision even for sequences from considerably
               unknown organisms.},
  month     = oct,
  year      = 2019,
  url       = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1817-x},
  doi       = {10.1186/s13059-019-1817-x},
  pmc       = {PMC6805573},
  pmid      = 31640809,
  issn      = {1474-7596,1474-760X},
  language  = {en}
}
@article{Chaumeil2022-xx,
  title     = {{GTDB}-Tk {v2}: memory friendly classification with the genome
               taxonomy database},
  author    = {Chaumeil, Pierre-Alain and Mussig, Aaron J and Hugenholtz, Philip
               and Parks, Donovan H},
  journal   = {Bioinformatics (Oxford, England)},
  publisher = {Oxford University Press (OUP)},
  volume    = 38,
  number    = 23,
  pages     = {5315--5316},
  abstract  = {SUMMARY: The Genome Taxonomy Database (GTDB) and associated
               taxonomic classification toolkit (GTDB-Tk) have been widely
               adopted by the microbiology community. However, the growing size
               of the GTDB bacterial reference tree has resulted in GTDB-Tk
               requiring substantial amounts of memory (∼320 GB) which limits
               its adoption and ease of use. Here, we present an update to
               GTDB-Tk that uses a divide-and-conquer approach where user
               genomes are @MISC{Andrews2010-pd,
               title  = "{FastQC}: A quality control tool for high throughput sequence data",
               author = "Andrews, Simon",
               year   =  2010,
               url    = "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
               }
               initially placed into a bacterial reference tree with
               family-level representatives followed by placement into an
               appropriate class-level subtree comprising species
               representatives. This substantially reduces the memory
               requirements of GTDB-Tk while having minimal impact on
               classification. AVAILABILITY AND IMPLEMENTATION: GTDB-Tk is
               implemented in Python and licenced under the GNU General Public
               Licence v3.0. Source code and documentation are available at:
               https://github.com/ecogenomics/gtdbtk. SUPPLEMENTARY INFORMATION:
               Supplementary data are available at Bioinformatics online.},
  month     = nov,
  year      = 2022,
  url       = {https://pubmed.ncbi.nlm.nih.gov/36218463/},
  doi       = {10.1093/bioinformatics/btac672},
  pmc       = {PMC9710552},
  pmid      = 36218463,
  issn      = {1367-4803,1367-4811},
  language  = {en}
}
@misc{Andrews2010-pd,
  title  = {{FastQC}: A quality control tool for high throughput sequence data},
  author = {Andrews, Simon},
  year   = 2010,
  url    = {http://www.bioinformatics.babraham.ac.uk/projects/fastqc/}
}
@article{Antipov2016-xw,
  title     = {{hybridSPAdes}: an algorithm for hybrid assembly of short and
               long reads},
  author    = {Antipov, Dmitry and Korobeynikov, Anton and McLean, Jeffrey S and
               Pevzner, Pavel A},
  journal   = {Bioinformatics (Oxford, England)},
  publisher = {Oxford Academic},
  volume    = 32,
  number    = 7,
  pages     = {1009--1015},
  abstract  = {MOTIVATION: Recent advances in single molecule real-time (SMRT)
               and nanopore sequencing technologies have enabled high-quality
               assemblies from long and inaccurate reads. However, these
               approaches require high coverage by long reads and remain
               expensive. On the other hand, the inexpensive short reads
               technologies produce accurate but fragmented assemblies. Thus, a
               hybrid approach that assembles long reads (with low coverage) and
               short reads has a potential to generate high-quality assemblies
               at reduced cost. RESULTS: We describe hybridSPAdes algorithm for
               assembling short and long reads and benchmark it on a variety of
               bacterial assembly projects. Our results demonstrate that
               hybridSPAdes generates accurate assemblies (even in projects with
               relatively low coverage by long reads) thus reducing the overall
               cost of genome sequencing. We further present the first complete
               assembly of a genome from single cells using SMRT reads.
               AVAILABILITY AND IMPLEMENTATION: hybridSPAdes is implemented in
               C++ as a part of SPAdes genome assembler and is publicly
               available at http://bioinf.spbau.ru/en/spades CONTACT:
               d.antipov@spbu.ru SUPPLEMENTARY INFORMATION: supplementary data
               are available at Bioinformatics online.},
  month     = apr,
  year      = 2016,
  url       = {https://academic.oup.com/bioinformatics/article-pdf/32/7/1009/49018455/bioinformatics_32_7_1009.pdf},
  doi       = {10.1093/bioinformatics/btv688},
  pmc       = {PMC4907386},
  pmid      = 26589280,
  issn      = {1367-4803,1367-4811},
  language  = {en}
}
@article{Orakov2021-yq,
  title    = {{GUNC}: detection of chimerism and contamination in prokaryotic
              genomes},
  author   = {Orakov, Askarbek and Fullam, Anthony and Coelho, Luis Pedro and
              Khedkar, Supriya and Szklarczyk, Damian and Mende, Daniel R and
              Schmidt, Thomas S B and Bork, Peer},
  journal  = {Genome biology},
  volume   = 22,
  number   = 1,
  pages    = 178,
  abstract = {Genomes are critical units in microbiology, yet ascertaining
              quality in prokaryotic genome assemblies remains a formidable
              challenge. We present GUNC (the Genome UNClutterer), a tool that
              accurately detects and quantifies genome chimerism based on the
              lineage homogeneity of individual contigs using a genome's full
              complement of genes. GUNC complements existing approaches by
              targeting previously underdetected types of contamination: we
              conservatively estimate that 5.7\% of genomes in GenBank, 5.2\% in
              RefSeq, and 15-30\% of pre-filtered ``high-quality''
              metagenome-assembled genomes in recent studies are undetected
              chimeras. GUNC provides a fast and robust tool to substantially
              improve prokaryotic genome quality.},
  month    = jun,
  year     = 2021,
  url      = {http://dx.doi.org/10.1186/s13059-021-02393-0},
  keywords = {Bioinformatics; Genome contamination; Genome quality;
              Metagenome-assembled genomes; Metagenomics},
  doi      = {10.1186/s13059-021-02393-0},
  pmc      = {PMC8201837},
  pmid     = 34120611,
  issn     = {1465-6906},
  language = {en}
}
@article{Parks2015-zg,
  title    = {{CheckM}: assessing the quality of microbial genomes recovered
              from isolates, single cells, and metagenomes},
  author   = {Parks, Donovan H and Imelfort, Michael and Skennerton, Connor T
              and Hugenholtz, Philip and Tyson, Gene W},
  journal  = {Genome research},
  volume   = 25,
  number   = 7,
  pages    = {1043--1055},
  abstract = {Large-scale recovery of genomes from isolates, single cells, and
              metagenomic data has been made possible by advances in
              computational methods and substantial reductions in sequencing
              costs. Although this increasing breadth of draft genomes is
              providing key information regarding the evolutionary and
              functional diversity of microbial life, it has become impractical
              to finish all available reference genomes. Making robust
              biological inferences from draft genomes requires accurate
              estimates of their completeness and contamination. Current methods
              for assessing genome quality are ad hoc and generally make use of
              a limited number of ``marker'' genes conserved across all
              bacterial or archaeal genomes. Here we introduce CheckM, an
              automated method for assessing the quality of a genome using a
              broader set of marker genes specific to the position of a genome
              within a reference genome tree and information about the
              collocation of these genes. We demonstrate the effectiveness of
              CheckM using synthetic data and a wide range of isolate-,
              single-cell-, and metagenome-derived genomes. CheckM is shown to
              provide accurate estimates of genome completeness and
              contamination and to outperform existing approaches. Using CheckM,
              we identify a diverse range of errors currently impacting publicly
              available isolate genomes and demonstrate that genomes obtained
              from single cells and metagenomic data vary substantially in
              quality. In order to facilitate the use of draft genomes, we
              propose an objective measure of genome quality that can be used to
              select genomes suitable for specific gene- and genome-centric
              analyses of microbial communities.},
  month    = jul,
  year     = 2015,
  url      = {http://dx.doi.org/10.1101/gr.186072.114},
  doi      = {10.1101/gr.186072.114},
  pmc      = {PMC4484387},
  pmid     = 25977477,
  issn     = {1088-9051,1549-5469},
  language = {en}
}
@article{Simao2015-bs,
  title     = {{BUSCO}: assessing genome assembly and annotation completeness
               with single-copy orthologs},
  author    = {Simão, Felipe A and Waterhouse, Robert M and Ioannidis,
               Panagiotis and Kriventseva, Evgenia V and Zdobnov, Evgeny M},
  journal   = {Bioinformatics (Oxford, England)},
  publisher = {Oxford University Press (OUP)},
  volume    = 31,
  number    = 19,
  pages     = {3210--3212},
  abstract  = {MOTIVATION: Genomics has revolutionized biological research, but
               quality assessment of the resulting assembled sequences is
               complicated and remains mostly limited to technical measures like
               N50. RESULTS: We propose a measure for quantitative assessment of
               genome assembly and annotation completeness based on
               evolutionarily informed expectations of gene content. We
               implemented the assessment procedure in open-source software,
               with sets of Benchmarking Universal Single-Copy Orthologs, named
               BUSCO. AVAILABILITY AND IMPLEMENTATION: Software implemented in
               Python and datasets available for download from
               http://busco.ezlab.org. CONTACT: evgeny.zdobnov@unige.ch
               SUPPLEMENTARY INFORMATION: Supplementary data are available at
               Bioinformatics online.},
  month     = oct,
  year      = 2015,
  url       = {https://academic.oup.com/bioinformatics/article/31/19/3210/211866},
  doi       = {10.1093/bioinformatics/btv351},
  pmid      = 26059717,
  issn      = {1367-4803,1367-4811},
  language  = {en}
}
@article{Uritskiy2018-ut,
  title     = {{MetaWRAP}-a flexible pipeline for genome-resolved metagenomic
               data analysis},
  author    = {Uritskiy, Gherman V and DiRuggiero, Jocelyne and Taylor, James},
  journal   = {Microbiome},
  publisher = {Springer Science and Business Media LLC},
  volume    = 6,
  number    = 1,
  pages     = 158,
  abstract  = {BACKGROUND: The study of microbiomes using whole-metagenome
               shotgun sequencing enables the analysis of uncultivated microbial
               populations that may have important roles in their environments.
               Extracting individual draft genomes (bins) facilitates
               metagenomic analysis at the single genome level. Software and
               pipelines for such analysis have become diverse and
               sophisticated, resulting in a significant burden for biologists
               to access and use them. Furthermore, while bin extraction
               algorithms are rapidly improving, there is still a lack of tools
               for their evaluation and visualization. RESULTS: To address these
               challenges, we present metaWRAP, a modular pipeline software for
               shotgun metagenomic data analysis. MetaWRAP deploys
               state-of-the-art software to handle metagenomic data processing
               starting from raw sequencing reads and ending in metagenomic bins
               and their analysis. MetaWRAP is flexible enough to give
               investigators control over the analysis, while still being
               easy-to-install and easy-to-use. It includes hybrid algorithms
               that leverage the strengths of a variety of software to extract
               and refine high-quality bins from metagenomic data through bin
               consolidation and reassembly. MetaWRAP's hybrid bin extraction
               algorithm outperforms individual binning approaches and other bin
               consolidation programs in both synthetic and real data sets.
               Finally, metaWRAP comes with numerous modules for the analysis of
               metagenomic bins, including taxonomy assignment, abundance
               estimation, functional annotation, and visualization.
               CONCLUSIONS: MetaWRAP is an easy-to-use modular pipeline that
               automates the core tasks in metagenomic analysis, while
               contributing significant improvements to the extraction and
               interpretation of high-quality metagenomic bins. The bin
               refinement and reassembly modules of metaWRAP consistently
               outperform other binning approaches. Each module of metaWRAP is
               also a standalone component, making it a flexible and versatile
               tool for tackling metagenomic shotgun sequencing data. MetaWRAP
               is open-source software available at
               https://github.com/bxlab/metaWRAP .},
  month     = sep,
  year      = 2018,
  url       = {https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-018-0541-1},
  keywords  = {Bin; Binning; Draft genome; Metagenome; Metagenomics; Pipeline;
               Reassembly; WGS},
  doi       = {10.1186/s40168-018-0541-1},
  pmc       = {PMC6138922},
  pmid      = 30219103,
  issn      = {2049-2618,2049-2618},
  language  = {en}
}@article{Steinegger2017-qt,
  title     = {{MMseqs2} enables sensitive protein sequence searching for the
               analysis of massive data sets},
  author    = {Steinegger, Martin and Söding, Johannes},
  journal   = {Nature biotechnology},
  publisher = {Nature Publishing Group},
  volume    = 35,
  number    = 11,
  pages     = {1026--1028},
  month     = nov,
  year      = 2017,
  url       = {https://www.nature.com/articles/nbt.3988},
  doi       = {10.1038/nbt.3988},
  pmid      = 29035372,
  issn      = {1087-0156,1546-1696},
  language  = {en}
}
@article{Bos2014-xe,
  title    = {Pre-Columbian mycobacterial genomes reveal seals as a source of
              New World human tuberculosis},
  author   = {Bos, Kirsten I and Harkins, Kelly M and Herbig, Alexander and
              Coscolla, Mireia and Weber, Nico and Comas, Iñaki and Forrest,
              Stephen A and Bryant, Josephine M and Harris, Simon R and
              Schuenemann, Verena J and Campbell, Tessa J and Majander, Kerttu
              and Wilbur, Alicia K and Guichon, Ricardo A and Wolfe Steadman,
              Dawnie L and Cook, Della Collins and Niemann, Stefan and Behr,
              Marcel A and Zumarraga, Martin and Bastida, Ricardo and Huson,
              Daniel and Nieselt, Kay and Young, Douglas and Parkhill, Julian
              and Buikstra, Jane E and Gagneux, Sebastien and Stone, Anne C and
              Krause, Johannes},
  journal  = {Nature},
  volume   = 514,
  number   = 7523,
  pages    = {494--497},
  abstract = {Modern strains of Mycobacterium tuberculosis from the Americas are
              closely related to those from Europe, supporting the assumption
              that human tuberculosis was introduced post-contact. This notion,
              however, is incompatible with archaeological evidence of
              pre-contact tuberculosis in the New World. Comparative genomics of
              modern isolates suggests that M. tuberculosis attained its
              worldwide distribution following human dispersals out of Africa
              during the Pleistocene epoch, although this has yet to be
              confirmed with ancient calibration points. Here we present three
              1,000-year-old mycobacterial genomes from Peruvian human
              skeletons, revealing that a member of the M. tuberculosis complex
              caused human disease before contact. The ancient strains are
              distinct from known human-adapted forms and are most closely
              related to those adapted to seals and sea lions. Two independent
              dating approaches suggest a most recent common ancestor for the M.
              tuberculosis complex less than 6,000 years ago, which supports a
              Holocene dispersal of the disease. Our results implicate sea
              mammals as having played a role in transmitting the disease to
              humans across the ocean.},
  month    = oct,
  year     = 2014,
  url      = {http://dx.doi.org/10.1038/nature13591},
  doi      = {10.1038/nature13591},
  pmc      = {PMC4550673},
  pmid     = 25141181,
  issn     = {0028-0836,1476-4687},
  language = {en}
}
@article{Garcia2020-wq,
  title     = {Sarek: A portable workflow for whole-genome sequencing analysis
               of germline and somatic variants},
  author    = {Garcia, Maxime and Juhos, Szilveszter and Larsson, Malin and
               Olason, Pall I and Martin, Marcel and Eisfeldt, Jesper and
               DiLorenzo, Sebastian and Sandgren, Johanna and Díaz De Ståhl,
               Teresita and Ewels, Philip and Wirta, Valtteri and Nistér, Monica
               and Käller, Max and Nystedt, Björn},
  journal   = {F1000Research},
  publisher = {F1000 Research Ltd},
  volume    = 9,
  number    = 63,
  pages     = 63,
  abstract  = {Whole-genome sequencing (WGS) is a fundamental technology for
               research to advance precision medicine, but the limited
               availability of portable and user-friendly workflows for WGS
               analyses poses a major challenge for many research groups and
               hampers scientific progress. Here we present Sarek, an
               open-source workflow to detect germline variants and somatic
               mutations based on sequencing data from WGS, whole-exome
               sequencing (WES), or gene panels. Sarek features (i) easy
               installation, (ii) robust portability across different computer
               environments, (iii) comprehensive documentation, (iv) transparent
               and easy-to-read code, and (v) extensive quality metrics
               reporting. Sarek is implemented in the Nextflow workflow language
               and supports both Docker and Singularity containers as well as
               Conda environments, making it ideal for easy deployment on any
               POSIX-compatible computers and cloud compute environments. Sarek
               follows the GATK best-practice recommendations for read alignment
               and pre-processing, and includes a wide range of software for the
               identification and annotation of germline and somatic
               single-nucleotide variants, insertion and deletion variants,
               structural variants, tumour sample purity, and variations in
               ploidy and copy number. Sarek offers easy, efficient, and
               reproducible WGS analyses, and can readily be used both as a
               production workflow at sequencing facilities and as a powerful
               stand-alone tool for individual research groups. The Sarek source
               code, documentation and installation instructions are freely
               available at https://github.com/nf-core/sarek and at
               https://nf-co.re/sarek/.},
  month     = sep,
  year      = 2020,
  url       = {https://f1000research.com/articles/9-63/pdf},
  keywords  = {Analysis workflow, Whole Genome Sequencing, Germline variants,
               Somatic variants, Cancer},
  doi       = {10.12688/f1000research.16665.2},
  issn      = {2046-1402},
  language  = {en}
}
@article{Hanssen2024-ul,
  title     = {Scalable and efficient {DNA} sequencing analysis on different
               compute infrastructures aiding variant discovery},
  author    = {Hanssen, Friederike and Garcia, Maxime U and Folkersen, Lasse and
               Pedersen, Anders Sune and Lescai, Francesco and Jodoin, Susanne
               and Miller, Edmund and Seybold, Matthias and Wacker, Oskar and
               Smith, Nicholas and Gabernet, Gisela and Nahnsen, Sven},
  journal   = {NAR genomics and bioinformatics},
  publisher = {Oxford University Press (OUP)},
  volume    = 6,
  number    = 2,
  pages     = {lqae031},
  abstract  = {DNA variation analysis has become indispensable in many aspects
               of modern biomedicine, most prominently in the comparison of
               normal and tumor samples. Thousands of samples are collected in
               local sequencing efforts and public databases requiring highly
               scalable, portable, and automated workflows for streamlined
               processing. Here, we present nf-core/sarek 3, a well-established,
               comprehensive variant calling and annotation pipeline for
               germline and somatic samples. It is suitable for any genome with
               a known reference. We present a full rewrite of the original
               pipeline showing a significant reduction of storage requirements
               by using the CRAM format and runtime by increasing intra-sample
               parallelization. Both are leading to a 70\% cost reduction in
               commercial clouds enabling users to do large-scale and
               cross-platform data analysis while keeping costs and CO2
               emissions low. The code is available at https://nf-co.re/sarek.},
  month     = jun,
  year      = 2024,
  url       = {https://academic.oup.com/nargab/article/6/2/lqae031/7658070},
  doi       = {10.1093/nargab/lqae031},
  pmc       = {PMC11044436},
  pmid      = 38666213,
  issn      = {2631-9268},
  language  = {en}
}

@article{Klapper2023-nv,
  title     = {Natural products from reconstructed bacterial genomes of the
               Middle and Upper Paleolithic},
  author    = {Klapper, Martin and Hübner, Alexander and Ibrahim, Anan and
               Wasmuth, Ina and Borry, Maxime and Haensch, Veit G and Zhang,
               Shuaibing and Al-Jammal, Walid K and Suma, Harikumar and Fellows
               Yates, James A and Frangenberg, Jasmin and Velsko, Irina M and
               Chowdhury, Somak and Herbst, Rosa and Bratovanov, Evgeni V and
               Dahse, Hans-Martin and Horch, Therese and Hertweck, Christian and
               González Morales, Manuel Ramon and Straus, Lawrence Guy and
               Vilotijevic, Ivan and Warinner, Christina and Stallforth, Pierre},
  journal   = {Science (New York, N.Y.)},
  publisher = {American Association for the Advancement of Science},
  pages     = {eadf5300},
  abstract  = {Major advances over the past decade in the field of ancient DNA
               are providing access to past paleogenomic diversity, but the
               diverse functions and biosynthetic capabilities of this growing
               paleome remain largely elusive. Here, we investigated the dental
               calculus of 12 Neanderthals and 52 anatomically modern humans
               spanning 100 kya to the present and reconstructed 459 bacterial
               metagenome-assembled genomes (MAGs). We identified a biosynthetic
               gene cluster (BGC) shared by seven Middle and Upper Paleolithic
               individuals that allows for the heterologous production of a
               class of previously unknown metabolites we name paleofurans. This
               paleobiotechnological approach demonstrates that viable
               biosynthetic machinery can be produced from the preserved genetic
               material of ancient organisms, allowing access to natural
               products from the Pleistocene and providing a promising area for
               natural product exploration.},
  month     = may,
  year      = 2023,
  url       = {https://www.science.org/doi/10.1126/science.adf5300},
  doi       = {10.1126/science.adf5300},
  pmid      = 37141315,
  issn      = {0036-8075,1095-9203},
  language  = {en}
}
